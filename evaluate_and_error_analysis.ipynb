{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f13d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "sentiment\n",
      "Positive    2000\n",
      "Neutral     1500\n",
      "Negative    1500\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "‚úÖ DONE\n",
      "Accuracy : 0.9948\n",
      "Macro-F1 : 0.9947\n",
      "\n",
      "üìä Error type summary:\n",
      "- ambiguous / short text: 16\n",
      "- informal / noise: 9\n",
      "- sarcasm / irony: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "MODEL_PATH = \"outputs/LogisticRegression.joblib\"   # ‡∏´‡∏£‡∏∑‡∏≠ LinearSVM.joblib\n",
    "DATA_PATH = \"data/2.synthetic_wisesight_like_thai_sentiment_hard_5000 (1).csv\"\n",
    "OUT_DIR = \"outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"sentiment\"\n",
    "\n",
    "# =========================\n",
    "# UTIL\n",
    "# =========================\n",
    "def clean(text):\n",
    "    \"\"\"Minimal preprocessing: whitespace normalization only\"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", str(text)).strip()\n",
    "\n",
    "def plot_cm(cm, labels, path):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xticks(range(len(labels)), labels, rotation=30)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# LOAD MODEL\n",
    "# =========================\n",
    "bundle = joblib.load(MODEL_PATH)\n",
    "pipe = bundle[\"pipeline\"]\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df = pd.read_csv(DATA_PATH)[[TEXT_COL, LABEL_COL]].dropna()\n",
    "df[TEXT_COL] = df[TEXT_COL].apply(clean)\n",
    "\n",
    "print(\"Label distribution:\")\n",
    "print(df[LABEL_COL].value_counts(), \"\\n\")\n",
    "\n",
    "# =========================\n",
    "# PREDICT\n",
    "# =========================\n",
    "y_true = df[LABEL_COL].values\n",
    "y_pred = pipe.predict(df[TEXT_COL])\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "print(\"‚úÖ DONE\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Macro-F1 : {macro_f1:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# CONFUSION MATRIX\n",
    "# =========================\n",
    "labels = sorted(df[LABEL_COL].unique())\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "plot_cm(cm, labels, os.path.join(OUT_DIR, \"confusion_matrix.png\"))\n",
    "\n",
    "# =========================\n",
    "# ERROR ANALYSIS\n",
    "# =========================\n",
    "conf = np.zeros(len(y_pred))\n",
    "\n",
    "if hasattr(pipe, \"predict_proba\"):\n",
    "    proba = pipe.predict_proba(df[TEXT_COL])\n",
    "    conf = proba.max(axis=1)\n",
    "\n",
    "err_df = pd.DataFrame({\n",
    "    \"text\": df[TEXT_COL],\n",
    "    \"true_label\": y_true,\n",
    "    \"pred_label\": y_pred,\n",
    "    \"confidence\": conf\n",
    "})\n",
    "\n",
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î\n",
    "err_df = err_df[err_df.true_label != err_df.pred_label]\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ï‡πà‡∏≥ ‚Üí ‡∏™‡∏π‡∏á\n",
    "err_df = err_df.sort_values(\"confidence\")\n",
    "\n",
    "# üî• ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 10 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏à‡∏≠ negation / sarcasm\n",
    "errN = err_df.head(30).copy()\n",
    "\n",
    "# =========================\n",
    "# ERROR TYPE HEURISTIC\n",
    "# =========================\n",
    "NEGATION_WORDS = [\n",
    "    \"‡πÑ‡∏°‡πà\", \"‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ\", \"‡πÑ‡∏°‡πà‡∏°‡∏µ\", \"‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢\", \"‡πÑ‡∏°‡πà‡πÄ‡∏•‡∏¢\", \"‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà\"\n",
    "]\n",
    "\n",
    "SARCASM_PATTERNS = [\n",
    "    \"‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏ô‡∏∞\", \"‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡πÄ‡∏•‡∏¢\", \"‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å\",\n",
    "    \"555\", \"‡∏Æ‡πà‡∏≤‡πÜ\", \"üòÇ\", \"ü§£\",\n",
    "    \"‡πÄ‡∏ô‡∏≠‡∏∞\", \"‡∏≠‡∏∞‡∏ô‡∏∞\", \"‡πÄ‡∏´‡∏≠‡∏∞\"\n",
    "]\n",
    "\n",
    "INFORMAL_NOISE = [\n",
    "    \"‡πÜ\", \"‡∏°‡∏≤‡∏Å‡∏Å‡∏Å\", \"‡∏à‡∏±‡∏á‡∏á‡∏á\", \"‡πÇ‡∏Ñ‡∏ï‡∏£\", \"‡∏™‡∏∏‡∏î‡πÜ\"\n",
    "]\n",
    "\n",
    "def classify_error(text):\n",
    "    text = str(text)\n",
    "\n",
    "    # 1Ô∏è‚É£ sarcasm / irony (‡∏ï‡∏£‡∏ß‡∏à‡∏Å‡πà‡∏≠‡∏ô!)\n",
    "    if any(p in text for p in SARCASM_PATTERNS):\n",
    "        return \"sarcasm / irony\"\n",
    "\n",
    "    # 2Ô∏è‚É£ negation\n",
    "    if any(w in text for w in NEGATION_WORDS):\n",
    "        return \"negation\"\n",
    "\n",
    "    # 3Ô∏è‚É£ informal / noise\n",
    "    if any(n in text for n in INFORMAL_NOISE):\n",
    "        return \"informal / noise\"\n",
    "\n",
    "    # 4Ô∏è‚É£ ambiguous / short\n",
    "    if len(text.split()) <= 3:\n",
    "        return \"ambiguous / short text\"\n",
    "\n",
    "    return \"other\"\n",
    "\n",
    "errN[\"error_type\"] = errN[\"text\"].apply(classify_error)\n",
    "\n",
    "# =========================\n",
    "# SAVE OUTPUTS\n",
    "# =========================\n",
    "\n",
    "# üëâ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 10 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "errN.head(10).to_csv(\n",
    "    os.path.join(OUT_DIR, \"misclassified_10.csv\"),\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "# üëâ summary ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "summary = errN[\"error_type\"].value_counts().to_dict()\n",
    "\n",
    "with open(os.path.join(OUT_DIR, \"error_summary.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nüìä Error type summary:\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"- {k}: {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
